import pg from "pg";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";

dotenv.config();

const { Pool } = pg;

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Connexion √† la base de donn√©es
const pool = new Pool({
  host: "dpg-d3cpaq24d50c73coqc70-a.frankfurt-postgres.render.com",
  port: 5432,
  database: "magiloc",
  user: "magiloc_user",
  password: "WXI3h9gX0txmMzmOIo3bho6L6MmeEeXb",
  ssl: { rejectUnauthorized: false }
});

async function runMigration() {
  try {
    console.log("üöÄ D√©marrage de la migration...");

    // Lire le fichier SQL
    const migrationPath = path.join(__dirname, "database", "add_history_tables.sql");
    const migrationSQL = fs.readFileSync(migrationPath, "utf8");

    console.log("üìÑ Fichier SQL charg√©");

    // Ex√©cuter la migration
    await pool.query(migrationSQL);

    console.log("‚úÖ Migration ex√©cut√©e avec succ√®s !");
    console.log("üìä Tables cr√©√©es/modifi√©es :");
    console.log("   - equipments (colonne note_retour ajout√©e)");
    console.log("   - location_history (colonnes am√©lior√©es)");
    console.log("   - maintenance_history (table cr√©√©e)");
    console.log("   - Index optimis√©s cr√©√©s");

    // V√©rifier les tables
    const result = await pool.query(`
      SELECT table_name
      FROM information_schema.tables
      WHERE table_schema = 'public'
      AND table_name IN ('equipments', 'location_history', 'maintenance_history')
      ORDER BY table_name
    `);

    console.log("\nüìã Tables pr√©sentes dans la base :");
    result.rows.forEach(row => console.log(`   ‚úì ${row.table_name}`));

    process.exit(0);
  } catch (error) {
    console.error("‚ùå Erreur lors de la migration:", error);
    process.exit(1);
  }
}

runMigration();
